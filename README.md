# ADM-HW4 Group#28
# Homework 4 - Nguyen Phu Hien, Nagham Almagout

### Saved data
All the saved data from scraping is compressed inside the filesadm.rar. It includes all of our data in pkl format.

### Data
The webpage from which we scraped for information is [here](https://www.immobiliare.it/vendita-case/roma/?criterio=rilevanza&pag=1)
We also scraped for the description of each house by the mylinks.pkl files.

### Additional data
For part 2 we used the passwords2.txt file which can be downloaded from [here](https://drive.google.com/file/d/1wTmOU-yqk4qdQYg42AquhzgpNGrRA96d/view)

### Task
This homework is divided into 2 seperate parts:
> 1. First part is about doing clustering (KMeans) based on the information we scrape
> 2. Second part is to find the duplicate passwords using hash function

#### Remark: 
If you have trouble viewing the ipynb on github, please use the [nbviewer](http://nbviewer.jupyter.org/). In fact, we recommend you use the nbviewer links since the ipynb files are large in size. Here are:
[Part1](http://nbviewer.jupyter.org/github/nguyenphuhien13/ADM-HW4/blob/master/HW4-Part1.ipynb)
[Part2](http://nbviewer.jupyter.org/github/nguyenphuhien13/ADM-HW4/blob/master/HW4-Part2.ipynb)

## Script Description
1. `HW4-Part1`:
> A jupyter notebook file for: 1) Does basic house information reflect house's description?

2. `HW4-Part2`:
> A jupyter notebook file for: 2) Find the duplicates!

3. `myfunction.py`:
> The function file

4.`Files adm.rar`:
> A rar file of scraped data
